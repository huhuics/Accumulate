# 库存系统设计相关    
## 一、库存什么时候进行预占/扣减？    
商家销售的商品数量有限，用户下单后商品数量会被扣减，举个例子，一件商品有1000个库存，现在有1000个用户，每个用户计划同时购买1000个。    
+ **方案1：** 如果用户加入购物车时进行库存预占，那么将只能有1个用户将1000个商品加入购物车    
+ **方案2：** 如果用户提交订单时进行库存预占，那么将也只能有1个用户将1000个商品提单成功，其他人均显示“库存不足，提单失败”    
+ **方案3：** 如果用户提交订单&支付成功时进行库存预存，那么这1000个人都能生成订单，但是只有1个人支付成功，其它订单会被自动取消    

一般采用**方案2**，理由如下：    
方案1用户可能只是暂时加入购物车，并不表示用户最终会购买。    

方案3会造成生成1000个订单，无论是在支付前校验库存还是支付成功后，都会造成用户准备好支付条件后出现99.9%的系统取消订单的概率，99.9%的用户体验不好。    

一般情况下用户提交订单不支付的概率要远小于加入购物车不购买，可以给用户预留最长支付时间，比如30分钟，超过30分钟系统自动取消订单，释放预占的库存。    

综上所述，方案2也可能由于用户下单预占库存但最终不支付，造成30分钟后预占库存的释放，但相比于方案1和3，方案2无疑是折中的最好方案。    

## 二、重复提交订单怎么处理？    
重复提交订单会造成库存重复扣减，超卖和少卖都会给商家带来损失。可能出现重复提交订单的情况及处理方式：    
+ 1.**用户善意行为：** 用户单击“提交订单”按钮后由于后端接口没有返回，用户以为没有操作成功再次单击“提交订单”按钮    
    - App端在用户第一次点击“提交订单”后对按钮进行置灰，禁止再次提交订单    
    
+ 2.**用户恶意行为：** 恶意用户绕过APP端防重功能，直接刷提单接口    
    - 采用令牌机制，用户每次进入结算页，提单系统会颁发一个令牌ID（全局唯一），当用户点击“提交订单”时这个令牌ID会传到后台系统进行校验，如果令牌ID存在 & 令牌ID访问次数==1才继续处理后续逻辑，否则直接返回    
    
+ 3.**提单系统重试：** 比如提单系统为提高系统可用性，第一次提单后接口没有响应系统自动重试    
    - 这种情况需要后端系统接口保证幂等性    
    
## 三、库存数据回滚    
+ 1.**用户未支付：** 用户下单后后悔了    
+ 2.**用户支付后取消：** 用户支付&支付后后悔了    
+ 3.**风控取消：** 风控识别异常行为，强制取消订单    
+ 4.**耦合系统故障：** 比如提交订单时系统T1同时会调用积分扣减系统X1、库存扣减系统X2、优惠券系统X3，加入X1、X2成功后，调用X3失败，需要回滚X1与X2.    
其中场景1、2、3比较类似，订单取消后发送MQ出来，各个系统保证自己能够正确消费订单取消MQ即可。    

场景4订单尚未生成，相对复杂一些：提单系统T1需要主动发起X1、X2的回滚请求，X1、X2回滚接口需要支持幂等性。    

针对场景4还存在一种极端情况，如果T1准备回滚时自身也宕机了，那么X1、X2就必须依靠自己来完成回滚操作了，也就是说系统必须具备自我数据健康检查的能力。具体做法可以通过worker机制，每个40分钟（这里的40一定要大于容忍用户的支付时间）进行数据健康检查，有异常进行回滚操作。    

## 四、多人同时购买1件商品，如何安全地扣减库存？    
**伪代码1：**
```java
  synchronized (this) {
      long stockNum = getProductStockNum(productId);
      if (stockNum > requestBuyNum) {
          String sql = " update stock_table" + 
                       " set stockNum = stockNum - " + requestBuyNum + 
                       " where productId = " + productId;
          int ret = updateSQL(sql);
          if (ret == 1) {
              return "扣减成功";
          } else {
              return "扣减失败";
          }
      }
  }
```    

伪代码1的设计思想是所有请求过来之后首先加锁，强制其串行处理，效率一定不高。    

**伪代码2：**    
```java
  String sql = " update stock_table" + 
               " set stockNum = stockNum - " + requestBuyNum + 
               " where productId = " + productId + 
               " and stockNum >= " + requestBuyNum;
  int ret = updateSQL(sql);
  if (ret == 1) {
      return "扣减成功";
  } else {
      return "扣减失败";
  }
```    

伪代码2只是在where条件里面加了`and stockNum >= requestBuyNum`即可防止超卖的行为，达到与伪代码1的功能。    

## 五、秒杀
如果商品是促销品（比如秒杀的商品）并发扣减的几率会更高，那么数据库的压力会更高，这个时候怎么做呢？    

海量的用户秒杀请求，**本质上是一个排序**，即先到先得。但是如此多的请求，注定了有些人是抢不到的，可以在进入上述伪代码DAO层前增加一个计数器控制，比如有50%的流量直接告诉其抢购失败。

```java
  public class SeckillService {
      private long count = 0;

      public BuyResult buy(User user, int productId, int productNum) {
          count++;
          if (count % 2 == 1) {
              Thread.sleep(1000);
              return new BuyResult("抢购失败");
          } else {
              return doBuy(User, productId, productNum);
          }
      }
  }
```    

同一个用户不允许多次抢购同一件商品，又该怎么做呢？    

```java
  public BuyResult buy(User user, int productId, int productNum) {
      //用户除了第一次进入时值为1，其它时候均大于1
      int tmp = redis.incr(user.getUid() + productId);
      if (tmp == 1) {
          //1小时后key自动销毁
          redis.expire(user.getUid() + productId, 3600);
          return doBuy(User, productId, productNum);
      } else {
          return new BuyResult("抢购失败");
      }
  }
```    

如果同一个用户拥有不同的账号来抢购同一件商品，上面的策略就失效了。一个用户很容易注册很多个账号，也即是网络所谓“僵尸账号”，数量多，如果使用几万个“将是账号”混进去抢购，这样大大提升抢到的概率，这该如何应对？    

```java
  public BuyResult buy(User user, int productId, int productNum) {
      String minuteKey = DateTimeUtil.getDateTimeStr("yyyyMMddHHmm");
      int minuteIpCount = redis.incr(minuteKey + user.getClientIp());

      //threshold为每分钟允许单个ip的最大访问次数
      if (minuteIpCount > threshold) {
          //识别到了潜在的风险用户时，会强制跳转到验证码页面进行校验
          return verifyUser(user);
      } else {
          return doBuy(User, productId, productNum);
      }
  }
```    

## 六、高并发设计的几个原则    
+ 服务接口的无状态化设计，方便随时随地可以进行水平扩容    
+ 服务接口的幂等性设计，防止重复提交造成的重复扣减    
+ 服务接口的限流与截流设计，应对异常流量造成整个系统瘫痪    
+ 针对读多写少的场景进行数据缓存，缓存时还应该注意缓存击穿的问题    
+ 订单数据持续增多势必要考虑分库分表，分库分表路由规则设计：    
    - 一定要紧贴业务，否则在一些聚合查询上非常麻烦
    - 避免短期内出现二次扩容的可能性    
    - 使用ElasticSearch集群，对数据进行全文索引，方便查询    
    




